{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZhyklnQXgU6"
   },
   "source": [
    "**SENTIMENT ANALYSIS FOR HATE SPEECH DETECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ofolae_TXZfT",
    "outputId": "136a9d2b-3bb4-41ea-f101-ccdcb42e5e17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ayush's\n",
      "[nltk_data]     Workhorse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk_B06pq_Yr8",
    "outputId": "f279a368-f1d3-4101-ce20-e65945980102"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ayush's\n",
      "[nltk_data]     Workhorse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Error loading plunkt: Package 'plunkt' not found in index\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ayush's\n",
      "[nltk_data]     Workhorse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('plunkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f5GsHYQsXq3l",
    "outputId": "7e31b1b2-79e3-49f4-cae9-88e4dc5aa17e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afcqVDAgh8OS"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-UW0RWoh8PU"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Cj9zJ314hL-O"
   },
   "outputs": [],
   "source": [
    "def delete_similar(inp, pat):\n",
    "    r = re.findall(pat, inp)\n",
    "    for i in r:\n",
    "        inp = re.sub(i, '', inp)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dhYXMO1d738Y",
    "outputId": "d62bb7f3-dd0b-4f7e-d11a-4ace3efb92e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can't use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Data_without_user']=np.vectorize(delete_similar)(train_data['tweet'],\"@[\\w]*\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Wa6uwWTW8k1N",
    "outputId": "b6b4eabd-a213-4129-b8f0-bd8c73e61cec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can't use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Data_without_user'] = train_data['Data_without_user'].apply(lambda x: x.lower())\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6S8o0OA89N2z",
    "outputId": "19895f43-da87-4728-a5f2-8ee787aceb70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for  lyft credit i can t use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3   model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now     motivation  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Data_without_user'] = train_data['Data_without_user'].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rzw3dk-Y900w",
    "outputId": "f30b4128-fc9e-4a9e-bc31-48c8a0c66124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for  lyft credit i can t use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3   model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now     motivation  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Data_without_user'] = train_data['Data_without_user'].apply(lambda x: re.sub(r'[^a-zA-Z]',' ',x))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Iaz2krXu-Fj2"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "fd0ghxyf-ZGr",
    "outputId": "e6ce3e2f-af90-459f-849f-502aad5969e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tokenized_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
       "      <td>[thanks, for, lyft, credit, i, can, t, use, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, i, love, u, take, with, u, all, the, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0    when a father is dysfunctional and is so sel...   \n",
       "1    thanks for  lyft credit i can t use cause th...   \n",
       "2                                bihday your majesty   \n",
       "3   model   i love u take with u all the time in ...   \n",
       "4             factsguide  society now     motivation   \n",
       "\n",
       "                                      tokenized_data  \n",
       "0  [when, a, father, is, dysfunctional, and, is, ...  \n",
       "1  [thanks, for, lyft, credit, i, can, t, use, ca...  \n",
       "2                            [bihday, your, majesty]  \n",
       "3  [model, i, love, u, take, with, u, all, the, t...  \n",
       "4             [factsguide, society, now, motivation]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tokenized_data'] = train_data['Data_without_user'].apply(lambda x: word_tokenize(x))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8Q72AO6-mXA",
    "outputId": "8ad6feba-fd57-4ceb-eb20-14397ca0bbd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "vW4-axVN_tZS",
    "outputId": "2ed21b7c-4bee-497a-f1b0-7b57ff212895"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tokenized_data</th>\n",
       "      <th>Data_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
       "      <td>[thanks, for, lyft, credit, i, can, t, use, ca...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, i, love, u, take, with, u, all, the, t...</td>\n",
       "      <td>[model, love, u, take, u, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0    when a father is dysfunctional and is so sel...   \n",
       "1    thanks for  lyft credit i can t use cause th...   \n",
       "2                                bihday your majesty   \n",
       "3   model   i love u take with u all the time in ...   \n",
       "4             factsguide  society now     motivation   \n",
       "\n",
       "                                      tokenized_data  \\\n",
       "0  [when, a, father, is, dysfunctional, and, is, ...   \n",
       "1  [thanks, for, lyft, credit, i, can, t, use, ca...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, u, take, with, u, all, the, t...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                              Data_without_stopwords  \n",
       "0  [father, dysfunctional, selfish, drags, kids, ...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                [model, love, u, take, u, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Data_without_stopwords'] = train_data['tokenized_data'].apply(lambda x: [i for i in x if not i in stop_words])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6KoyuHAyARHA"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "lm4MVm3wAVev",
    "outputId": "f87b59a5-f933-481b-a074-eda87631cb0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tokenized_data</th>\n",
       "      <th>Data_without_stopwords</th>\n",
       "      <th>stemmed_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
       "      <td>[thanks, for, lyft, credit, i, can, t, use, ca...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>thank lyft credit use caus offer wheelchair va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>bihday majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, i, love, u, take, with, u, all, the, t...</td>\n",
       "      <td>[model, love, u, take, u, time, ur]</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>factsguid societi motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0    when a father is dysfunctional and is so sel...   \n",
       "1    thanks for  lyft credit i can t use cause th...   \n",
       "2                                bihday your majesty   \n",
       "3   model   i love u take with u all the time in ...   \n",
       "4             factsguide  society now     motivation   \n",
       "\n",
       "                                      tokenized_data  \\\n",
       "0  [when, a, father, is, dysfunctional, and, is, ...   \n",
       "1  [thanks, for, lyft, credit, i, can, t, use, ca...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, u, take, with, u, all, the, t...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                              Data_without_stopwords  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                [model, love, u, take, u, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                        stemmed_data  \n",
       "0      father dysfunct selfish drag kid dysfunct run  \n",
       "1  thank lyft credit use caus offer wheelchair va...  \n",
       "2                                     bihday majesti  \n",
       "3                        model love u take u time ur  \n",
       "4                            factsguid societi motiv  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['stemmed_data'] = train_data['Data_without_stopwords'].apply(lambda x:' '.join([stemming.stem(i) for i in x]))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ePZu2izRAp3Q"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizing = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "B0ao4F_gA1BI",
    "outputId": "8f44ee28-220e-4ace-dbd5-cb750efa9f75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tokenized_data</th>\n",
       "      <th>Data_without_stopwords</th>\n",
       "      <th>stemmed_data</th>\n",
       "      <th>lemmatized_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit i can t use cause th...</td>\n",
       "      <td>[thanks, for, lyft, credit, i, can, t, use, ca...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>thank lyft credit use caus offer wheelchair va...</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>bihday majesti</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, i, love, u, take, with, u, all, the, t...</td>\n",
       "      <td>[model, love, u, take, u, time, ur]</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>factsguid societi motiv</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0    when a father is dysfunctional and is so sel...   \n",
       "1    thanks for  lyft credit i can t use cause th...   \n",
       "2                                bihday your majesty   \n",
       "3   model   i love u take with u all the time in ...   \n",
       "4             factsguide  society now     motivation   \n",
       "\n",
       "                                      tokenized_data  \\\n",
       "0  [when, a, father, is, dysfunctional, and, is, ...   \n",
       "1  [thanks, for, lyft, credit, i, can, t, use, ca...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, u, take, with, u, all, the, t...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                              Data_without_stopwords  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                [model, love, u, take, u, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                        stemmed_data  \\\n",
       "0      father dysfunct selfish drag kid dysfunct run   \n",
       "1  thank lyft credit use caus offer wheelchair va...   \n",
       "2                                     bihday majesti   \n",
       "3                        model love u take u time ur   \n",
       "4                            factsguid societi motiv   \n",
       "\n",
       "                                     lemmatized_data  \n",
       "0  father dysfunctional selfish drag kid dysfunct...  \n",
       "1  thanks lyft credit use cause offer wheelchair ...  \n",
       "2                                     bihday majesty  \n",
       "3                        model love u take u time ur  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['lemmatized_data'] = train_data['Data_without_stopwords'].apply(lambda x:' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGJc4GrCBaBJ",
    "outputId": "9d8b5f8e-f412-4180-f2d9-5bc809ed6155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.9, max_features=1000, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectoriser = CountVectorizer(max_df=0.90, min_df=2,max_features=1000,stop_words='english')\n",
    "vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rx9gzjHKCFOo",
    "outputId": "79047f93-b69d-4da3-9dd2-e8bffee1e3a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 134042 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstem = vectoriser.fit_transform(train_data['stemmed_data'])\n",
    "trainstem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi1UkwmACZ5b",
    "outputId": "b08982b9-f739-4c5d-c01e-15fc6ce92e0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 123672 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlem = vectoriser.fit_transform(train_data['lemmatized_data'])\n",
    "trainlem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4L6VqxP-Crd3",
    "outputId": "f0e94431-f69e-4d88-a236-0353ab5e1db3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstem.toarray()\n",
    "trainlem.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCNDbzHqCxY7",
    "outputId": "d260ab5d-c281-45fc-c194-474665249660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, max_features=1000, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectoriser = TfidfVectorizer(max_df=0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "tfidf_vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WXjJut2D3eN",
    "outputId": "f765056e-a7ef-4d5a-be30-9978dd0bfa88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintfidfstem = tfidf_vectoriser.fit_transform(train_data['stemmed_data'])\n",
    "traintfidfstem.toarray()\n",
    "traintfidflem = tfidf_vectoriser.fit_transform(train_data['lemmatized_data'])\n",
    "traintfidflem.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "uioTQVfpEdX5",
    "outputId": "32c873d0-b89a-4846-b5ac-ff8c17f48bff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid  #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1      31964   @user #white #supremacists want everyone to s...\n",
       "2      31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd #bihday to my amazing, hilarious #nephew...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory: left-right polarisation! #tru...\n",
       "17193  49156  feeling like a mermaid  #hairflip #neverre...\n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
       "17195  49158  happy, at work conference: right mindset leads...\n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "fo7A44NtEhqT",
    "outputId": "fe896200-d9af-464b-d3a9-639d36001eab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31968</td>\n",
       "      <td>choose to be   :) #momtips</td>\n",
       "      <td>choose to be   :) #momtips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31969</td>\n",
       "      <td>something inside me dies   eyes nes...</td>\n",
       "      <td>something inside me dies   eyes nes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31970</td>\n",
       "      <td>#finished#tattoo#inked#ink#loveit #...</td>\n",
       "      <td>#finished#tattoo#inked#ink#loveit #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31971</td>\n",
       "      <td>@user @user @user i will never understand why...</td>\n",
       "      <td>i will never understand why my dad left me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31972</td>\n",
       "      <td>#delicious   #food #lovelife #capetown mannaep...</td>\n",
       "      <td>#delicious   #food #lovelife #capetown mannaep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "5  31968                        choose to be   :) #momtips    \n",
       "6  31969  something inside me dies   eyes nes...   \n",
       "7  31970  #finished#tattoo#inked#ink#loveit #...   \n",
       "8  31971   @user @user @user i will never understand why...   \n",
       "9  31972  #delicious   #food #lovelife #capetown mannaep...   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0  #studiolife #aislife #requires #passion #dedic...  \n",
       "1    #white #supremacists want everyone to see th...  \n",
       "2  safe ways to heal your #acne!!    #altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4    3rd #bihday to my amazing, hilarious #nephew...  \n",
       "5                        choose to be   :) #momtips   \n",
       "6  something inside me dies   eyes nes...  \n",
       "7  #finished#tattoo#inked#ink#loveit #...  \n",
       "8      i will never understand why my dad left me...  \n",
       "9  #delicious   #food #lovelife #capetown mannaep...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Data_without_user'] = np.vectorize(delete_similar)(test_data['tweet'], \"@[\\w]*\")\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Xjrmv4p4j57S",
    "outputId": "5d92d393-14e1-4d58-f825-4f84ec689eed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0  #studiolife #aislife #requires #passion #dedic...  \n",
       "1    #white #supremacists want everyone to see th...  \n",
       "2  safe ways to heal your #acne!!    #altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4    3rd #bihday to my amazing, hilarious #nephew...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Data_without_user'] = test_data['Data_without_user'].apply(lambda x: x.lower())\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GWq5JuFskPSa",
    "outputId": "102fd3a1-c7a3-4167-9980-f4d7c594e8a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>3rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0   studiolife  aislife  requires  passion  dedic...  \n",
       "1     white  supremacists want everyone to see th...  \n",
       "2  safe ways to heal your  acne       altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4    3rd  bihday to my amazing  hilarious  nephew...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Data_without_user'] = test_data['Data_without_user'].apply(lambda x: re.sub(r'[^\\w\\s]',' ', x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xVd8iDrSkPYh",
    "outputId": "bcdf8f22-1b49-492f-a783-fed39b689e3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>3rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0   studiolife  aislife  requires  passion  dedic...  \n",
       "1     white  supremacists want everyone to see th...  \n",
       "2  safe ways to heal your  acne       altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4    3rd  bihday to my amazing  hilarious  nephew...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Data_without_user'] = test_data['Data_without_user'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ', x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XREJ9QkWkPeb",
    "outputId": "95a63299-2d40-4bf8-b4d1-ee28ae58bdea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \n",
       "0   studiolife  aislife  requires  passion  dedic...  \n",
       "1     white  supremacists want everyone to see th...  \n",
       "2  safe ways to heal your  acne       altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4     rd  bihday to my amazing  hilarious  nephew...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Data_without_user'] = test_data['Data_without_user'].apply(lambda x: re.sub(r'[^a-zA-Z]',' ',x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "OvGP0VOWkPib",
    "outputId": "7dfb95b6-b92e-4f19-db72-97cdf2886af5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone to see th...</td>\n",
       "      <td>[white, supremacists, want, everyone, to, see,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "      <td>[rd, bihday, to, my, amazing, hilarious, nephe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0   studiolife  aislife  requires  passion  dedic...   \n",
       "1     white  supremacists want everyone to see th...   \n",
       "2  safe ways to heal your  acne       altwaystohe...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4     rd  bihday to my amazing  hilarious  nephew...   \n",
       "\n",
       "                                         tweet_token  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1  [white, supremacists, want, everyone, to, see,...  \n",
       "2  [safe, ways, to, heal, your, acne, altwaystohe...  \n",
       "3  [is, the, hp, and, the, cursed, child, book, u...  \n",
       "4  [rd, bihday, to, my, amazing, hilarious, nephe...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['tweet_token'] = test_data['Data_without_user'].apply(lambda x: word_tokenize(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "YXwC5eMOkPl0",
    "outputId": "f240bde5-b010-4f0b-9582-2502ff1ba519"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>Data_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone to see th...</td>\n",
       "      <td>[white, supremacists, want, everyone, to, see,...</td>\n",
       "      <td>[white, supremacists, want, everyone, see, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
       "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
       "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "      <td>[rd, bihday, to, my, amazing, hilarious, nephe...</td>\n",
       "      <td>[rd, bihday, amazing, hilarious, nephew, eli, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0   studiolife  aislife  requires  passion  dedic...   \n",
       "1     white  supremacists want everyone to see th...   \n",
       "2  safe ways to heal your  acne       altwaystohe...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4     rd  bihday to my amazing  hilarious  nephew...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1  [white, supremacists, want, everyone, to, see,...   \n",
       "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
       "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
       "4  [rd, bihday, to, my, amazing, hilarious, nephe...   \n",
       "\n",
       "                              Data_without_stopwords  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1  [white, supremacists, want, everyone, see, new...  \n",
       "2  [safe, ways, heal, acne, altwaystoheal, health...  \n",
       "3  [hp, cursed, child, book, reservations, alread...  \n",
       "4  [rd, bihday, amazing, hilarious, nephew, eli, ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Data_without_stopwords'] = test_data['tweet_token'].apply(lambda x: [i for i in x if not i in stop_words])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwpsoApakPol",
    "outputId": "a0dd1813-6555-4e67-d8a1-05fe71e7a190"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolif aislif requir passion dedic willpow ...\n",
       "1     white supremacist want everyon see new bird movi\n",
       "2            safe way heal acn altwaystoh healthi heal\n",
       "3    hp curs child book reserv alreadi ye harrypott...\n",
       "4    rd bihday amaz hilari nephew eli ahmir uncl da...\n",
       "Name: tweet_stemmed, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['tweet_stemmed'] = test_data['Data_without_stopwords'].apply(lambda x: ' '.join([stemming.stem(i) for i in x]))\n",
    "test_data['tweet_stemmed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "-zvJL8q3kPrS",
    "outputId": "4673ee12-022c-46d7-e511-8838697f80f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Data_without_user</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>Data_without_stopwords</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>lemmatized_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>studiolif aislif requir passion dedic willpow ...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone to see th...</td>\n",
       "      <td>[white, supremacists, want, everyone, to, see,...</td>\n",
       "      <td>[white, supremacists, want, everyone, see, new...</td>\n",
       "      <td>white supremacist want everyon see new bird movi</td>\n",
       "      <td>white supremacist want everyone see new bird m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
       "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
       "      <td>safe way heal acn altwaystoh healthi heal</td>\n",
       "      <td>safe way heal acne altwaystoheal healthy healing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
       "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
       "      <td>hp curs child book reserv alreadi ye harrypott...</td>\n",
       "      <td>hp cursed child book reservation already yes h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "      <td>[rd, bihday, to, my, amazing, hilarious, nephe...</td>\n",
       "      <td>[rd, bihday, amazing, hilarious, nephew, eli, ...</td>\n",
       "      <td>rd bihday amaz hilari nephew eli ahmir uncl da...</td>\n",
       "      <td>rd bihday amazing hilarious nephew eli ahmir u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                   Data_without_user  \\\n",
       "0   studiolife  aislife  requires  passion  dedic...   \n",
       "1     white  supremacists want everyone to see th...   \n",
       "2  safe ways to heal your  acne       altwaystohe...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4     rd  bihday to my amazing  hilarious  nephew...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1  [white, supremacists, want, everyone, to, see,...   \n",
       "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
       "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
       "4  [rd, bihday, to, my, amazing, hilarious, nephe...   \n",
       "\n",
       "                              Data_without_stopwords  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1  [white, supremacists, want, everyone, see, new...   \n",
       "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
       "3  [hp, cursed, child, book, reservations, alread...   \n",
       "4  [rd, bihday, amazing, hilarious, nephew, eli, ...   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  studiolif aislif requir passion dedic willpow ...   \n",
       "1   white supremacist want everyon see new bird movi   \n",
       "2          safe way heal acn altwaystoh healthi heal   \n",
       "3  hp curs child book reserv alreadi ye harrypott...   \n",
       "4  rd bihday amaz hilari nephew eli ahmir uncl da...   \n",
       "\n",
       "                                     lemmatized_data  \n",
       "0  studiolife aislife requires passion dedication...  \n",
       "1  white supremacist want everyone see new bird m...  \n",
       "2   safe way heal acne altwaystoheal healthy healing  \n",
       "3  hp cursed child book reservation already yes h...  \n",
       "4  rd bihday amazing hilarious nephew eli ahmir u...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['lemmatized_data'] = test_data['Data_without_stopwords'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJra3HPDm7G-",
    "outputId": "c96bb04e-3e99-4324-dc3b-7412eb05e89c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.9, max_features=1000, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec_bow = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "vec_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joNUADfrm7KG",
    "outputId": "42afac2b-622b-4421-fc26-bc7dad6f6f2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bs = vec_bow.fit_transform(test_data['tweet_stemmed'])\n",
    "test_bs.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HU5kTNCCm7Nr",
    "outputId": "b75c70fd-73d7-4e7e-9782-db1f8e142e67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bl = vec_bow.fit_transform(test_data['lemmatized_data'])\n",
    "test_bl.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9XTqGbPm7Qv",
    "outputId": "bf700e33-7945-4daa-bffc-9f8dc2eebb8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, max_features=1000, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidfvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFCONSrxm7Th",
    "outputId": "7537a7b8-ae7f-4a52-a753-d0f607138c69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtfidf_stem = tfidfvec.fit_transform(test_data['tweet_stemmed'])\n",
    "testtfidf_stem.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00Lbt6Izm7WU",
    "outputId": "f5c92677-b790-4361-fc85-b00e8785828e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtfidf_lemm = tfidfvec.fit_transform(test_data['lemmatized_data'])\n",
    "testtfidf_lemm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ecGiuwTOm7Y6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "oorsOf0KpplL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.70171264, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.71246008, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=traintfidflem\n",
    "y=train_data['label']    \n",
    "k=X.toarray()\n",
    "k[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4cODX14Nppos"
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest=train_test_split(X,y,test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yTSoYBnppr4",
    "outputId": "18cdf5b2-4a32-4996-d033-dfa3978c28bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "GHHxFJyCppuk"
   },
   "outputs": [],
   "source": [
    "prediction_lr=lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEWYe5H3ppxG",
    "outputId": "3ed61ce2-0547-4761-9060-00c906fdcb34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9474389916867793\n",
      "[[10343   533]\n",
      " [   55   256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     10876\n",
      "           1       0.32      0.82      0.47       311\n",
      "\n",
      "    accuracy                           0.95     11187\n",
      "   macro avg       0.66      0.89      0.72     11187\n",
      "weighted avg       0.98      0.95      0.96     11187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(prediction_lr, ytest))\n",
    "print(confusion_matrix(prediction_lr, ytest))\n",
    "print(classification_report(prediction_lr, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "U38OaoKZppzW"
   },
   "outputs": [],
   "source": [
    "svc=SVC()\n",
    "svc.fit(xtrain,ytrain)\n",
    "predict_svc=svc.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdqE3jtfqjfj",
    "outputId": "de9547b0-d198-486b-d3bc-ad67cb355c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495843389648699\n",
      "[[10339   505]\n",
      " [   59   284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     10844\n",
      "           1       0.36      0.83      0.50       343\n",
      "\n",
      "    accuracy                           0.95     11187\n",
      "   macro avg       0.68      0.89      0.74     11187\n",
      "weighted avg       0.97      0.95      0.96     11187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predict_svc, ytest))\n",
    "print(confusion_matrix(predict_svc, ytest))\n",
    "print(classification_report(predict_svc, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ZKxdGTY9qjiW"
   },
   "outputs": [],
   "source": [
    "nb=GaussianNB()\n",
    "nb.fit(xtrain.toarray(), ytrain)\n",
    "predict_nb=nb.predict(xtest.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHB87XFpqjk9",
    "outputId": "a13804ea-5d6a-4f25-d7f3-782ccfb68bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5820148386520068\n",
      "[[5796   74]\n",
      " [4602  715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71      5870\n",
      "           1       0.91      0.13      0.23      5317\n",
      "\n",
      "    accuracy                           0.58     11187\n",
      "   macro avg       0.73      0.56      0.47     11187\n",
      "weighted avg       0.72      0.58      0.49     11187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predict_nb, ytest))\n",
    "print(confusion_matrix(predict_nb, ytest))\n",
    "print(classification_report(predict_nb, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "rqFgOGuFqjnL"
   },
   "outputs": [],
   "source": [
    "X1=traintfidfstem\n",
    "y1=train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3_sS-Ygbqjpu"
   },
   "outputs": [],
   "source": [
    "x1train, x1test, y1train, y1test=train_test_split(X1, y1, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66WH4TkqqjsM",
    "outputId": "73af968e-b2e3-4428-be2b-1170bc95f379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1=LogisticRegression()\n",
    "lr1.fit(x1train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "zLJmwZiPqjun"
   },
   "outputs": [],
   "source": [
    "predict_lr1=lr1.predict(x1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8zUz5N1r4F6",
    "outputId": "f02b32cf-c780-458e-e070-dde578a2b75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9480647179762224\n",
      "[[10338   521]\n",
      " [   60   268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     10859\n",
      "           1       0.34      0.82      0.48       328\n",
      "\n",
      "    accuracy                           0.95     11187\n",
      "   macro avg       0.67      0.88      0.73     11187\n",
      "weighted avg       0.98      0.95      0.96     11187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predict_lr1, y1test))\n",
    "print(confusion_matrix(predict_lr1, y1test))\n",
    "print(classification_report(predict_lr1, y1test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "aj-RUim1r4Ik"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc1=SVC()\n",
    "svc1.fit(x1train,y1train)\n",
    "predict_svc1=svc1.predict(x1test)\n",
    "predict_svc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axwPAqu0r4LQ",
    "outputId": "6ab532be-d5b5-49f3-a090-ae1aca801d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9506570126039152\n",
      "[[10339   493]\n",
      " [   59   296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     10832\n",
      "           1       0.38      0.83      0.52       355\n",
      "\n",
      "    accuracy                           0.95     11187\n",
      "   macro avg       0.68      0.89      0.75     11187\n",
      "weighted avg       0.97      0.95      0.96     11187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predict_svc1, y1test))\n",
    "print(confusion_matrix(predict_svc1, y1test))\n",
    "print(classification_report(predict_svc1, y1test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ccjjkQp3r4Nn"
   },
   "outputs": [],
   "source": [
    "nb1=GaussianNB()\n",
    "nb1.fit(x1train.toarray(), y1train)\n",
    "predict_nb1=nb1.predict(x1test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcJ1hmIpr4Px",
    "outputId": "6cb34c42-3221-4ef3-f839-d5e1f4cc60f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5605613658711004\n",
      "[[5565   83]\n",
      " [4833  706]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.69      5648\n",
      "           1       0.89      0.13      0.22      5539\n",
      "\n",
      "    accuracy                           0.56     11187\n",
      "   macro avg       0.72      0.56      0.46     11187\n",
      "weighted avg       0.71      0.56      0.46     11187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predict_nb1, y1test))\n",
    "print(confusion_matrix(predict_nb1, y1test))\n",
    "print(classification_report(predict_nb1, y1test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoI8NkvHsk4c"
   },
   "source": [
    "test DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qg7XnO3Fsj7S",
    "outputId": "b78574d7-ed94-4b60-ac9e-7d6e7d38c428"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lr=lr.predict(testtfidf_lemm)\n",
    "test_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mEnh-NSsj-m",
    "outputId": "268ae966-6e81-40f9-b96e-3a8dabbdb38c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_svc=svc.predict(testtfidf_lemm)\n",
    "test_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSepnOYkskBV",
    "outputId": "9251b1e9-a0e1-4155-80cc-16af78395d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nb=nb.predict(testtfidf_lemm.toarray())\n",
    "test_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "dJ9nrpcRskES"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x1test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udqzd487skGt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sentimentanalysisforhatespeechdetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
